package jsonLoad
import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._
import scala.io.Source
import java.nio.charset.CodingErrorAction
import scala.io.Codec
import org.apache.spark.mllib.recommendation._


object mydataload {
 def addValue (line:String) : String = {
   var linest = 0
   var st = line.indexOf("link_data")
   if(st > 0) {linest = st + 13 }
   else {linest = 0}
   return line.substring((62),32)
 }
  
 def main(args: Array[String]) {
    
    // Set the log level to only print errors
    Logger.getLogger("org").setLevel(Level.ERROR)
    
     // Create a SparkContext using every core of the local machine
     val sc = new SparkContext("local[*]", "mydataload")
    
   
    val data = sc.textFile("./sample.json")
    
    //val ratings = data.map( x => x.split('\t') ).map( x => Rating(x(0).toInt, x(1).toInt, x(2).toDouble) ).cache()
      val ratings = data.map(x => addValue(x))
    
      ratings.collect().foreach(a => println(a))
    }
    
  

}
 
 
 
 
 


